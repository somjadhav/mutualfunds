{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to investing, comparing a fund's return to the S&P 500's return is often the best way to evaluate its performance. In this notebook, we will test out different machine learning techniques to see if we can predict, with a high degree of accuracy, whether or not a fund outperformed the S&P 500 from 2008 to 2018, a time period that included both a bull market and a bear market, and low and high commodity prices. While past performance does not guarantee future returns, it is safe to believe that over the long run, the value of most equity funds (ETFs and mutual funds with most of their assets in stocks) will appreciate. Therefore, if we can use machine learning to identify characteristics of these high performers, we may be able to use that data to predict whether or not a fund in the future will be able to outperform the S&P 500, something that could stand to make us a lot of money.\n",
    "\n",
    "The dataset (which I found on Kaggle) was scraped from Yahoo Finance and can be found [here](https://www.kaggle.com/stefanoleone992/mutual-funds-and-etfs).\n",
    "\n",
    "For a quick primer on what mutual funds and ETFs are, visit this [link](https://www.investopedia.com/articles/exchangetradedfunds/08/etf-mutual-fund-difference.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify what each column's data type is. This will help us when we transform some of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {'net_assets':np.float64, 'fund_yield':np.float64,\n",
    "       'net_annual_expense_ratio_fund':np.float64,'portfolio_stocks':np.float64,\n",
    "       'price_earnings':np.float64, 'price_book':np.float64, 'price_sales':np.float64, 'price_cashflow':np.float64,\n",
    "       'basic_materials':np.float64, 'consumer_cyclical':np.float64, 'financial_services':np.float64,\n",
    "       'real_estate':np.float64, 'consumer_defensive':np.float64, 'healthcare':np.float64, 'utilities':np.float64,\n",
    "       'communication_services':np.float64, 'energy':np.float64, 'industrials':np.float64, 'technology':np.float64, \n",
    "       'fund_beta_3years':np.float64, 'fund_beta_5years':np.float64, 'fund_beta_10years':np.float64,\n",
    "       'fund_standard_deviation_3years':np.float64, 'fund_standard_deviation_5years':np.float64,\n",
    "       'fund_standard_deviation_10years':np.float64, 'fund_return_10years':np.float64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25308"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file and get number of rows in dataset\n",
    "df_mf = pd.read_csv('mfdata.csv',dtype=col_types)\n",
    "df_mf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation/Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as we're trying to compare mutual funds to the S&P 500, we can only look at stock/equity mutual funds. Looking at the data, we can see that non-equity funds tend to have missing data for the 'investment' column. We also only want to look at rows which don't have missing data. Since returns are rarely 0, we will assume that a value of zero for the 10-year return is in fact, a missing value.\n",
    "\n",
    "Furthermore, we cannot consider any columns which are related to the return of the mutual fund, which means any rows with return data or any related metrics (Sharpe/Treynor ratio, alpha, fund $R^2$, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select mutual funds that have data for investment, are heavily invested in stocks, and aren't missing return data \n",
    "df_mf = df_mf[(df_mf['investment'] == 'Blend') | (df_mf['investment'] == 'Growth') | (df_mf['investment'] == 'Value')]\n",
    "df_mf = df_mf[(df_mf['portfolio_stocks'] + df_mf['portfolio_cash']) > 95]\n",
    "df_mf = df_mf[df_mf['portfolio_stocks'] > 80]\n",
    "df_mf = df_mf[df_mf['fund_return_10years'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of columns that we want to consider\n",
    "selected_columns = [\n",
    "       'net_assets', 'fund_yield', 'investment', 'size',\n",
    "       'net_annual_expense_ratio_fund','portfolio_stocks',\n",
    "       'price_earnings', 'price_book', 'price_sales', 'price_cashflow',\n",
    "       'basic_materials', 'consumer_cyclical', 'financial_services',\n",
    "       'real_estate', 'consumer_defensive', 'healthcare', 'utilities',\n",
    "       'communication_services', 'energy', 'industrials', 'technology', 'fund_beta_3years',\n",
    "       'fund_beta_5years', 'fund_beta_10years',\n",
    "       'fund_standard_deviation_3years', 'fund_standard_deviation_5years',\n",
    "       'fund_standard_deviation_10years', 'fund_return_10years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf = df_mf[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8558"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of rows in this subset\n",
    "df_mf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows with missing data\n",
    "df_mf.shape[0] - df_mf.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows with missing data after those rows have been dropped\n",
    "df_mf.shape[0] - df_mf.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate y values from features\n",
    "s_rets = df_mf['fund_return_10years']\n",
    "df_mf = df_mf.drop('fund_return_10years',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5494479680526192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert y values to binary variable for classification\n",
    "# see the distribution of 1s and 0s to make sure it is not lopsided\n",
    "# 13.6 is the 10 year (08-18) return of the S&P 500\n",
    "s_rets = s_rets > 13.6\n",
    "s_rets = s_rets.astype(int)\n",
    "sum(s_rets)/len(s_rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data for net assets, we see that the range of values is from the low tens of millions to the trillions. Now, since we don't want this feature to single-handedly affect the outcome of our classification model, we need to transform the data in this column. Taking the log of the data makes the spread more reasonable, so we will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_mf['net_assets'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mf['net_assets'] = df_mf['net_assets'].apply(lambda x: math.log(x))\n",
    "\n",
    "plt.hist(df_mf['net_assets'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many machine learning models cannot handle categorical data, we need to convert data in those columns to numerical data, which we will do through one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_assets</th>\n",
       "      <th>fund_yield</th>\n",
       "      <th>net_annual_expense_ratio_fund</th>\n",
       "      <th>portfolio_stocks</th>\n",
       "      <th>price_earnings</th>\n",
       "      <th>price_book</th>\n",
       "      <th>price_sales</th>\n",
       "      <th>price_cashflow</th>\n",
       "      <th>basic_materials</th>\n",
       "      <th>consumer_cyclical</th>\n",
       "      <th>...</th>\n",
       "      <th>fund_beta_10years</th>\n",
       "      <th>fund_standard_deviation_3years</th>\n",
       "      <th>fund_standard_deviation_5years</th>\n",
       "      <th>fund_standard_deviation_10years</th>\n",
       "      <th>investment_Blend</th>\n",
       "      <th>investment_Growth</th>\n",
       "      <th>investment_Value</th>\n",
       "      <th>size_Large</th>\n",
       "      <th>size_Medium</th>\n",
       "      <th>size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.800227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>97.06</td>\n",
       "      <td>24.49</td>\n",
       "      <td>5.78</td>\n",
       "      <td>4.45</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>13.36</td>\n",
       "      <td>13.40</td>\n",
       "      <td>14.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.265780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>99.99</td>\n",
       "      <td>12.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10.20</td>\n",
       "      <td>7.56</td>\n",
       "      <td>29.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.01</td>\n",
       "      <td>13.76</td>\n",
       "      <td>17.00</td>\n",
       "      <td>20.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.163775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>95.43</td>\n",
       "      <td>12.69</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.37</td>\n",
       "      <td>15.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1.21</td>\n",
       "      <td>14.53</td>\n",
       "      <td>14.40</td>\n",
       "      <td>16.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16.064695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>89.52</td>\n",
       "      <td>26.07</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.06</td>\n",
       "      <td>16.87</td>\n",
       "      <td>5.56</td>\n",
       "      <td>12.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.94</td>\n",
       "      <td>12.14</td>\n",
       "      <td>17.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22.481124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>94.77</td>\n",
       "      <td>12.54</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.67</td>\n",
       "      <td>10.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09</td>\n",
       "      <td>12.88</td>\n",
       "      <td>13.06</td>\n",
       "      <td>14.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    net_assets  fund_yield  net_annual_expense_ratio_fund  portfolio_stocks  \\\n",
       "2    20.800227         0.0                           1.15             97.06   \n",
       "24   18.265780         1.0                           1.79             99.99   \n",
       "26   20.163775         1.0                           0.86             95.43   \n",
       "30   16.064695         0.0                           1.95             89.52   \n",
       "35   22.481124         2.0                           0.62             94.77   \n",
       "\n",
       "    price_earnings  price_book  price_sales  price_cashflow  basic_materials  \\\n",
       "2            24.49        5.78         4.45           14.29             0.00   \n",
       "24           12.29        1.61         0.85           10.20             7.56   \n",
       "26           12.69        1.53         0.92            5.03             4.37   \n",
       "30           26.07        3.46         2.06           16.87             5.56   \n",
       "35           12.54        1.76         1.23            3.69             3.67   \n",
       "\n",
       "    consumer_cyclical  ...  fund_beta_10years  fund_standard_deviation_3years  \\\n",
       "2               20.20  ...               1.11                           13.36   \n",
       "24              29.10  ...               1.01                           13.76   \n",
       "26              15.77  ...               1.21                           14.53   \n",
       "30              12.50  ...               1.06                           12.94   \n",
       "35              10.58  ...               1.09                           12.88   \n",
       "\n",
       "    fund_standard_deviation_5years  fund_standard_deviation_10years  \\\n",
       "2                            13.40                            14.89   \n",
       "24                           17.00                            20.17   \n",
       "26                           14.40                            16.23   \n",
       "30                           12.14                            17.56   \n",
       "35                           13.06                            14.31   \n",
       "\n",
       "    investment_Blend  investment_Growth  investment_Value  size_Large  \\\n",
       "2                  0                  1                 0           1   \n",
       "24                 1                  0                 0           1   \n",
       "26                 0                  0                 1           0   \n",
       "30                 0                  1                 0           0   \n",
       "35                 0                  0                 1           1   \n",
       "\n",
       "    size_Medium  size_Small  \n",
       "2             0           0  \n",
       "24            0           0  \n",
       "26            1           0  \n",
       "30            1           0  \n",
       "35            0           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_dummies = pd.get_dummies(df_mf['investment'],prefix=\"investment\")\n",
    "size_dummies = pd.get_dummies(df_mf['size'],prefix=\"size\")\n",
    "\n",
    "df_mf = pd.concat([df_mf,investment_dummies,size_dummies], axis=1)\n",
    "df_mf = df_mf.drop(['investment','size'],axis=1)\n",
    "\n",
    "df_mf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the dataset into a training and test set. We will use the former to train the model, and the latter to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_mf, s_rets, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each column has different units, we need to scale the data in each column to a value between 0 and 1. To avoid the curse of dimensionality, we need to perform PCA on our feature space to transform our large dataset into a smaller one (referring to the number of columns here) that still captures most of the information in the larger one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.to_numpy())\n",
    "X_test_scaled = scaler.transform(X_test.to_numpy())\n",
    "\n",
    "pca = PCA(.95)\n",
    "\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# print number of columns in old and new datasets\n",
    "print(X_train_scaled.shape[1])\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training and Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, we will test out 6 different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_neighbors': 3}\n",
      "Average train accuracy: 89.796\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors' : list(range(3,52,2))}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(knn_clf,knn_params,cv=5,scoring='accuracy', n_jobs=-1)\n",
    "knn_gridsearch.fit(X_train_pca,y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",knn_gridsearch.best_params_)\n",
    "best_knn = knn_gridsearch.best_estimator_\n",
    "\n",
    "knn_accuracy = cross_val_score(best_knn,X_train_pca, y_train.to_numpy(), cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:', round(sum(knn_accuracy)/len(knn_accuracy)*100,3))\n",
    "\n",
    "knn_preds = best_knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[659 106]\n",
      " [ 61 877]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       765\n",
      "           1       0.89      0.93      0.91       938\n",
      "\n",
      "    accuracy                           0.90      1703\n",
      "   macro avg       0.90      0.90      0.90      1703\n",
      "weighted avg       0.90      0.90      0.90      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), knn_preds))\n",
    "print(classification_report(y_test.to_numpy(), knn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 100, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Average train accuracy: 85.288\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_params = {\n",
    "    'C':[0.1,0.5,1,5,10,50,100],\n",
    "    'gamma':['scale','auto'],\n",
    "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree':[1,2,3,4,5]\n",
    "}\n",
    "\n",
    "svm_gridsearch = GridSearchCV(svm_clf, svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "svm_gridsearch.fit(X_train_pca, y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",svm_gridsearch.best_params_)\n",
    "best_svm = svm_gridsearch.best_estimator_\n",
    "\n",
    "svm_accuracy = cross_val_score(best_svm, X_train_pca, y_train.to_numpy(), cv=5, scoring = 'accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:',round(sum(svm_accuracy)/len(svm_accuracy)*100,3))\n",
    "\n",
    "svm_preds = best_svm.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[601 164]\n",
      " [116 822]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81       765\n",
      "           1       0.83      0.88      0.85       938\n",
      "\n",
      "    accuracy                           0.84      1703\n",
      "   macro avg       0.84      0.83      0.83      1703\n",
      "weighted avg       0.84      0.84      0.83      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), svm_preds))\n",
    "print(classification_report(y_test.to_numpy(), svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Average train accuracy: 80.619\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=42)\n",
    "lr_params = {\n",
    "    'C':[0.1,0.5,1,5,10,50,100],\n",
    "    'penalty':['l2'],\n",
    "    'solver':['liblinear', 'sag', 'lbfgs', 'newton-cg']\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(lr_clf, lr_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "lr_gridsearch.fit(X_train_pca, y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",lr_gridsearch.best_params_)\n",
    "best_lr = lr_gridsearch.best_estimator_\n",
    "\n",
    "lr_accuracy = cross_val_score(best_lr, X_train_pca, y_train.to_numpy(), cv=5, scoring = 'accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:',round(sum(lr_accuracy)/len(lr_accuracy)*100,3))\n",
    "\n",
    "lr_preds = best_lr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[554 211]\n",
      " [160 778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75       765\n",
      "           1       0.79      0.83      0.81       938\n",
      "\n",
      "    accuracy                           0.78      1703\n",
      "   macro avg       0.78      0.78      0.78      1703\n",
      "weighted avg       0.78      0.78      0.78      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), lr_preds))\n",
    "print(classification_report(y_test.to_numpy(), lr_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'gini', 'max_depth': 15, 'max_features': 'log2', 'splitter': 'best'}\n",
      "Average train accuracy: 88.665\n"
     ]
    }
   ],
   "source": [
    "dtc_clf = DecisionTreeClassifier(random_state=42)\n",
    "dtc_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'splitter':['best','random'],\n",
    "    'max_depth':[5,10,15,20],\n",
    "    'max_features':['log2', 'sqrt'],\n",
    "    'min_samples_leaf':[5,10,15]\n",
    "}\n",
    "\n",
    "dtc_gridsearch = GridSearchCV(dtc_clf, dtc_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dtc_gridsearch.fit(X_train_pca, y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",dtc_gridsearch.best_params_)\n",
    "best_dtc = dtc_gridsearch.best_estimator_\n",
    "\n",
    "dtc_accuracy = cross_val_score(best_dtc, X_train_pca, y_train.to_numpy(), cv=5, scoring = 'accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:',round(sum(dtc_accuracy)/len(dtc_accuracy)*100,3))\n",
    "\n",
    "dtc_preds = best_dtc.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[656 109]\n",
      " [ 78 860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       765\n",
      "           1       0.89      0.92      0.90       938\n",
      "\n",
      "    accuracy                           0.89      1703\n",
      "   macro avg       0.89      0.89      0.89      1703\n",
      "weighted avg       0.89      0.89      0.89      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), dtc_preds))\n",
    "print(classification_report(y_test.to_numpy(), dtc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 500}\n",
      "Average train accuracy: 84.466\n"
     ]
    }
   ],
   "source": [
    "adb_clf = AdaBoostClassifier(random_state=42)\n",
    "adb_params = {'n_estimators':[50,100,200,300,500]}\n",
    "\n",
    "adb_gridsearch = GridSearchCV(adb_clf, adb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "adb_gridsearch.fit(X_train_pca, y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",adb_gridsearch.best_params_)\n",
    "best_adb = adb_gridsearch.best_estimator_\n",
    "\n",
    "adb_accuracy = cross_val_score(best_adb, X_train_pca, y_train.to_numpy(), cv=5, scoring = 'accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:',round(sum(adb_accuracy)/len(adb_accuracy)*100,3))\n",
    "\n",
    "adb_preds = best_adb.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[598 167]\n",
      " [107 831]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81       765\n",
      "           1       0.83      0.89      0.86       938\n",
      "\n",
      "    accuracy                           0.84      1703\n",
      "   macro avg       0.84      0.83      0.84      1703\n",
      "weighted avg       0.84      0.84      0.84      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), adb_preds))\n",
    "print(classification_report(y_test.to_numpy(), adb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 5, 'n_estimators': 200}\n",
      "Average train accuracy: 90.647\n"
     ]
    }
   ],
   "source": [
    "rdf_clf = RandomForestClassifier(random_state=42)\n",
    "rdf_params = {\n",
    "    'n_estimators':[50,100,200],\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[5,10,15,20],\n",
    "    'max_features':['log2', 'sqrt'],\n",
    "    'min_samples_leaf':[5,10,15]\n",
    "}\n",
    "\n",
    "\n",
    "rdf_gridsearch = GridSearchCV(rdf_clf, rdf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rdf_gridsearch.fit(X_train_pca, y_train.to_numpy())\n",
    "\n",
    "print(\"Best params:\",rdf_gridsearch.best_params_)\n",
    "best_rdf = rdf_gridsearch.best_estimator_\n",
    "\n",
    "rdf_accuracy = cross_val_score(best_rdf, X_train_pca, y_train.to_numpy(), cv=5, scoring = 'accuracy', n_jobs=-1)\n",
    "print('Average train accuracy:',round(sum(rdf_accuracy)/len(rdf_accuracy)*100,3))\n",
    "\n",
    "rdf_preds = best_rdf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[671  94]\n",
      " [ 57 881]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       765\n",
      "           1       0.90      0.94      0.92       938\n",
      "\n",
      "    accuracy                           0.91      1703\n",
      "   macro avg       0.91      0.91      0.91      1703\n",
      "weighted avg       0.91      0.91      0.91      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.to_numpy(), rdf_preds))\n",
    "print(classification_report(y_test.to_numpy(), rdf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing out the 6 different models, the results show that the RandomForest model is the best. It has the highest accuracy for both the train and test set, and it seems to avoid overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model on ETF data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing we should do is test our best model on ETF data. ETFs are similar to mutual funds, but still differ in their trading mechanism, liquidity, and management approach. Therefore, we expect ETFs and mutual funds that have similar characteristics to have similar returns, which in turn, should not affect our model's performance too much. That being said, it is reasonable to assume that the model's performance will not be as good as its performance on the mutual fund data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2352"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data and get number of rows\n",
    "df_etfs = pd.read_csv('ETFs.csv',dtype=col_types)\n",
    "df_etfs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows that contain equity heavy funds with data for the investment column\n",
    "df_etfs = df_etfs[(df_etfs['investment'] == 'Blend') | (df_etfs['investment'] == 'Growth') | (df_etfs['investment'] == 'Value')]\n",
    "df_etfs = df_etfs[df_etfs['portfolio_stocks'] > 90]\n",
    "df_etfs = df_etfs[df_etfs['fund_return_10years'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get data for certain columns\n",
    "df_etfs = df_etfs[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of rows in subset\n",
    "df_etfs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows with missing data\n",
    "# since this number is a small fraction of the total number of rows,\n",
    "# we can just drop these rows from the dataset\n",
    "df_etfs.shape[0] - df_etfs.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etfs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dependent variables from features\n",
    "s_rets_etf = df_etfs['fund_return_10years']\n",
    "df_etfs = df_etfs.drop('fund_return_10years',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.446"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class labels and see how balanced the distribition of labels is\n",
    "s_rets_etf = s_rets_etf > 13.6\n",
    "s_rets_etf = s_rets_etf.astype(int)\n",
    "sum(s_rets_etf)/len(s_rets_etf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we transformed the net assets column for the mutual fund data, we must do the same to the ETF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_etfs['net_assets'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_etfs['net_assets'] = df_etfs['net_assets'].apply(lambda x: math.log(x))\n",
    "\n",
    "plt.hist(df_etfs['net_assets'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same goes for creating dummy variables for investment and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_assets</th>\n",
       "      <th>fund_yield</th>\n",
       "      <th>net_annual_expense_ratio_fund</th>\n",
       "      <th>portfolio_stocks</th>\n",
       "      <th>price_earnings</th>\n",
       "      <th>price_book</th>\n",
       "      <th>price_sales</th>\n",
       "      <th>price_cashflow</th>\n",
       "      <th>basic_materials</th>\n",
       "      <th>consumer_cyclical</th>\n",
       "      <th>...</th>\n",
       "      <th>fund_beta_10years</th>\n",
       "      <th>fund_standard_deviation_3years</th>\n",
       "      <th>fund_standard_deviation_5years</th>\n",
       "      <th>fund_standard_deviation_10years</th>\n",
       "      <th>investment_Blend</th>\n",
       "      <th>investment_Growth</th>\n",
       "      <th>investment_Value</th>\n",
       "      <th>size_Large</th>\n",
       "      <th>size_Medium</th>\n",
       "      <th>size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.019812</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>12.92</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.41</td>\n",
       "      <td>7.81</td>\n",
       "      <td>17.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.762818</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.05</td>\n",
       "      <td>99.99</td>\n",
       "      <td>12.92</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.41</td>\n",
       "      <td>7.81</td>\n",
       "      <td>17.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.947429</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.08</td>\n",
       "      <td>12.92</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.44</td>\n",
       "      <td>7.74</td>\n",
       "      <td>17.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.375591</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11.34</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4.06</td>\n",
       "      <td>2.41</td>\n",
       "      <td>14.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>15.16</td>\n",
       "      <td>16.21</td>\n",
       "      <td>18.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.904993</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.90</td>\n",
       "      <td>11.34</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.44</td>\n",
       "      <td>14.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>15.16</td>\n",
       "      <td>16.22</td>\n",
       "      <td>18.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   net_assets  fund_yield  net_annual_expense_ratio_fund  portfolio_stocks  \\\n",
       "0   29.019812        1.84                           0.00            100.00   \n",
       "1   29.762818        1.77                           0.05             99.99   \n",
       "2   28.947429        1.84                           0.00             99.08   \n",
       "3   21.375591        2.57                           0.00            100.00   \n",
       "4   21.904993        1.82                           0.00             99.90   \n",
       "\n",
       "   price_earnings  price_book  price_sales  price_cashflow  basic_materials  \\\n",
       "0           12.92        1.18         0.81            5.41             7.81   \n",
       "1           12.92        1.18         0.81            5.41             7.81   \n",
       "2           12.92        1.18         0.81            5.44             7.74   \n",
       "3           11.34        1.12         1.07            4.06             2.41   \n",
       "4           11.34        1.12         1.07            4.07             2.44   \n",
       "\n",
       "   consumer_cyclical  ...  fund_beta_10years  fund_standard_deviation_3years  \\\n",
       "0              17.26  ...               0.99                           14.38   \n",
       "1              17.26  ...               0.98                           14.38   \n",
       "2              17.33  ...               0.99                           14.38   \n",
       "3              14.25  ...               1.06                           15.16   \n",
       "4              14.26  ...               1.06                           15.16   \n",
       "\n",
       "   fund_standard_deviation_5years  fund_standard_deviation_10years  \\\n",
       "0                           14.75                            16.89   \n",
       "1                           14.75                            16.83   \n",
       "2                           14.75                            16.90   \n",
       "3                           16.21                            18.39   \n",
       "4                           16.22                            18.38   \n",
       "\n",
       "   investment_Blend  investment_Growth  investment_Value  size_Large  \\\n",
       "0                 1                  0                 0           1   \n",
       "1                 1                  0                 0           1   \n",
       "2                 1                  0                 0           1   \n",
       "3                 1                  0                 0           1   \n",
       "4                 1                  0                 0           1   \n",
       "\n",
       "   size_Medium  size_Small  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_dummies = pd.get_dummies(df_etfs['investment'],prefix=\"investment\")\n",
    "size_dummies = pd.get_dummies(df_etfs['size'],prefix=\"size\")\n",
    "\n",
    "df_etfs = pd.concat([df_etfs,investment_dummies,size_dummies], axis=1)\n",
    "df_etfs = df_etfs.drop(['investment','size'],axis=1)\n",
    "df_etfs.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df_etfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same scaler and PCA transformation to the ETF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etfs_scaled = scaler.transform(df_etfs.to_numpy())\n",
    "X_etfs_pca = pca.transform(X_etfs_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Random Forest Classifier we trained and tested before to predict whether or not each ETF will outperform the S&P 500 over 10 years. Then compare the predictions to the actual outcomes and see how our model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etf_acc = best_rdf.score(X_etfs_pca,s_rets_etf.to_numpy())\n",
    "etf_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there was a slight loss in performance, but not too severe. We can be assured that this model has some valid predictive power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
